% vim: set tw=78 tabstop=4 shiftwidth=4 aw ai:

\chapter{Protocol Measurements in Peer-to-Peer Systems}
\label{chapter:proto-measure}

Based on BitTorrent's success story (it has managed to become the number one
protocol of the internet in a matter of years), the scientific community has
delved heavily in analysing, understanding and improving its performance.
Research focus has ranged from measurements~\cite{measurement-study} to
protocol improvements~\cite{bt-impr}, from social
networking~\cite{tribler-social} to moderation
techniques~\cite{measurements-analysis}, from content distribution
enhancements~\cite{bitos} to network infrastructure impact~\cite{bt-impact}.

We undertook a novel approach involving client-side information collection
regarding client and protocol implementation. We have instrumented a
libtorrent-rasterbar
client\footnote{http://www.rasterbar.com/products/libtorrent/} and a
Tribler\footnote{http://www.tribler.org/trac/} client to provide verbose
information regarding BitTorrent protocol implementation. These results are
collected and subsequently processed and analysed through a rendering
interface.

Our aim is to measure and analyze protocol messages while in real-world
environments. As descriped in Chapter~\ref{chapter:virt-infra}, a virtualized
infrastructure had been used for realistic environments; apart from that
clients and trackers running in a real-world swarm have been used and
instrumented to provide valuable protocol information and parameters. No
simulators have been used for collecting, measuring and analyzing protocol
parameters, rather a ``keep it real as much as possible'' approach.
Information, messages and parameters are collected directly from peers and
tracker that are part of a real-world Peer-to-Peer swarm.

The action chronology for measuring parameters had been collecting data,
parsing and storing it and then subjecting protocol parameters to processing
and analysis. The rest of this chapter presents the measured parameters,
approaches to collecting, parsing and storing information into an ``easy to be
used'' format and then putting it to analysis and interpretation.

\section{BitTorrent Messages and Paramaters}
\label{sec:proto-measure:protocol-messages}

Analysis of BitTorrent client-centric behavior and, to some extent, swarm
behavior, is based on BitTorrent protocol
messages\footnote{http://www.bittorrent.org/beps/bep\_0003.html}. Messages are
used for handshaking, closing the connection, requesting and receiving data.

The BitTorrent client will generate at startup a unique identifier of itself,
known as \textit{peer id}. This is client dependent, each client encoding a
peer id based on its own implementation.

\subsection{Protocol Messages}

Each torrent is exclusively identified by a 20-byte SHA1 hash of the value of
the info key from the torrent file dictionary which is defined as \textit{info
hash}. The peer id and info hash values are important in the TCP connection
establishing and are typically logged by trackers.

The handshake is the first sent message. It uses the format:
\begin{verbatim}
<length><protocol><reserved><info_hash><peer_id>
\end{verbatim}

The protocol parameter represents the protocol identifier string and the
length parameter represents the protocol name length. Reserved represents
eight reserved bytes whose bits can be used to modify the behavior of the
protocol. Standard implementations use this as zero-filled.
\texttt{info\_hash} represents the identifier of the shared resource that is
desired by the initiator of the connection. \texttt{peer\_id} represents the
initiator's unique identifier.

The receiver of the handshake must verify the \texttt{info\_hash} in order to
decide if it can serve it. If it is not currently serving, it will drop the
connection.  Otherwise, the receiver will send its own handshake message to
the initiator of the connection. If the initiator receives a handshake whose
\texttt{peer\_id} does not match with the expected one -- it must keep a list
with peers addresses and ports and their corresponding \texttt{peer\_id}'s --
then it also must drop the connection.

Remaining protocol messages have the format:
\begin{verbatim}
<length><message ID><payload>
\end{verbatim}

The length prefix is a four byte big-endian value representing the sum of message ID and payload sizes. The message ID is a single decimal byte. The payload is message dependent.

\begin{itemize}

  \item \textbf{keep-alive} (\texttt{$<$len=0000$>$}) \\
    The Keep-alive message is the only message without any message ID and
    payload.  It is sent to maintain the connection alive if no other message
    has been sent for a given amount of time. The amount of time is about two
    minutes.

  \item \textbf{choke} (\texttt{$<$len=0001$>$$<$id=0$>$}) \\
    The Choke message is sent when the client wants to choke a remote peer.

  \item \textbf{unchoke} (\texttt{$<$len=0001$>$$<$id=1$>$}) \\
    The Unchoke message is sent when the client wants to unchoke a remote peer.

  \item \textbf{interested} (\texttt{$<$len=0001$>$$<$id=2$>$}) \\
    The Interested message is sent when the client is interested in something
    that the remote peer has to offer.

  \item \textbf{not interested} (\texttt{$<$len=0001$>$$<$id=2$>$}) \\
    The Not interested message is sent when the client is not interested in
    anything that the remote peer has to offer.

  \item \textbf{have} (\texttt{$<$len=0005$>$$<$id=4$>$$<$piece index$>$}) \\
    The piece index is a 4 bytes value representing the zero-based index of a
    piece that has just been successfully downloaded and verified via its hash
    value present in the torrent file.

  \item \textbf{bitfield} (\texttt{$<$len=0001+X$>$$<$id=5$>$$<$bitfield$>$}) \\
    The Bitfield message may only be sent immediately after the handshake
    sequence has occurred and before any other message is sent. It is optional
    and need not be sent if a client has no pieces. The Bitfield payload has
    the length X and its bits represent the pieces that have been successfully
    downloaded. The high bit in the first byte corresponds to piece index 0. A
    set bit indicates a valid and available piece, and a cleared bit indicates
    a missing piece. Any spare bits are set to zero.

  \item \textbf{request}
  (\texttt{$<$len=0013$>$$<$id=6$>$$<$index$>$$<$begin$>$$<$length$>$}) \\
    The Request message is sent when requesting a block. Index is the
    zero-based index of the piece containing the requested block, begin is the
    block offset inside the piece and length represents the block size.

  \item \textbf{piece}
  (\texttt{$<$len=0009+X$>$$<$id=7$>$$<$index$>$$<$begin$>$$<$block$>$}) \\
    The Piece message is sent when delivering a block to an interested peer.
    Index is the zero-based index of the piece containing the delivered block,
    begin is the block offset inside the piece and block represents the
    X-sized block data.

  \item \textbf{cancel}
  (\texttt{$<$len=0013$>$$<$id=8$>$$<$index$>$$<$begin$>$$<$length$>$}) \\
    The Cancel message is sent when canceling a block request sent before.
    Index is the zero-based index of the piece containing the requested block,
    begin is the block offset inside the piece and length represents the block
    size.

  \item \textbf{port} (\texttt{$<$len=0003$>$$<$id=9$>$$<$listen port$>$}) \\
The Port message is sent by clients that implement a DHT tracker. The listen port is the port of the client's DHT node listening on.

\end{itemize}

Swarm measured data are usually collected from trackers. While this offers a
global view of the swarm it has little information about client-centric
properties such as protocol implementation, neighbour set, number of connected
peers, etc. A more thorough approach has been presented by Iosup et
al.~\cite{corr-overlay}, using network probes to interrogate various clients.

Our approach, while not as scalable as the above mentioned one, aims to collect
client-centric data, store and analyse it in order to provide information on
the impact of network topology, protocol implementation and peer
characteristics. Our infrastructure provides micro-analysis, rather than
macro-analysis of a given swarm. We focus on detailed peer-centric properties,
rather than less-detailed global, tracker-centric information. The data
provided by controlled instrumented peers in a given swarm is retrieved,
parsed and stored for subsequent analysis.

We differentiate between two kinds of BitTorrent messages \textit{status
messages}, which clients provide periodically to report the current sessionâ€™s
download state, and \textit{verbose messages} that contain protocol messages
exchanged between peers (chokes, unchokes, peer connections, pieces transfer
etc.).

Another type of messages are those provided by tracker logging. Tracker-based
messages provide an overall view of the entire swarm, albeit at the cost of
less-detailed information. Tracker logging tipically consists of periodic
messages sent by clients as announce messages. However, these messages' period
is quite large (usually 30 minutes -- 1800 seconds) resulting in less detailed
information. Their overall swarm vision is an important addition to status and
verbose client messages.

\subsection{Measured Data and Parameters}

Data and parameters measured are those particular to BitTorrent clients and
swarms, that provide support for evalation and improvements at protocol level.
The measured parameters are described in the
Table~\ref{tab:proto-measure:status-messages-params},
Table~\ref{tab:proto-measure:verbose-messages-params} and
Table~\ref{tab:proto-measure:tracker-messages-params}, depending
on their source (either status messages, verbose messages or tracker
messages).

\begin{table}[htb]
  \centering
  \caption{Parameters from Status Messages}
  \label{tab:proto-measure:status-messages-params}
  \begin{tabular}{@{}ll@{}}
    \toprule
      \textbf{Parameter} & \textbf{Explanation} \\
    \midrule
      Download speed & Current peer download speed -- number of bytes
      received \\
      Upload speed & Current peer upload speed -- number of bytes sent \\
      ETA & How long before the complete file is received \\
      Number of connections & Number of remote peers currently connected to
      this client \\
      Download size & Bytes download so far \\
      Upload size & Bytes uploaded so far \\
      Remote peers ID & IP address and TCP port of remote peerd \\
      Per-remote peer download speed & Download speed of each remote connected
      peer \\
      Per-peer upload speed & Upload speed of each remote connected peer \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[htb]
  \centering
  \caption{Parameters from Verbose Messages}
  \label{tab:proto-measure:verbose-messages-params}
  \begin{tabular}{@{}ll@{}}
    \toprule
      \textbf{Parameter} & \textbf{Explanation} \\
    \midrule
      \texttt{CHOKE} & Disallow remote peer to request pieces \\
      \texttt{UNCHOKE} & Allow remote peer to request pieces \\
      \texttt{INTERESTED} & Mark interest in a certain piece \\
      \texttt{NOT\_INTERESTED} & Unmark interest in a certain piece \\
      \texttt{HAVE} & Remote peer possesses current piece \\
      \texttt{BITFIELD} & Bitmap of the file \\
      \texttt{REQUEST} & Ask for a given piece \\
      \texttt{PIECE} & Send piece \\
      \texttt{CANCEL} & Cancel request of a piece \\
      \texttt{DHT\_PORT} & Present DHT port to DHT-enabled peers \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[htb]
  \centering
  \caption{Parameters from Tracker Messages}
  \label{tab:proto-measure:tracker-messages-params}
  \begin{tabular}{@{}ll@{}}
    \toprule
      \textbf{Parameter} & \textbf{Explanation} \\
    \midrule
      Swarm size & The number of peers in the swarm \\
      Client IP/port & Remote peer identification (IP address and TCP port in
      used) \\
      Client type & BitTorrent implementation of each client \\
      Per-client download size & Download size for each client \\
      Per-client upload size & Upload size for each client \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Approaches to Collecting and Extracting Protocol Parameters}

Peer-to-Peer clients and applications may be instrumented to provide various
internal information that is available for analysis. This information may also
be provided by client logging enabled for the client. Such data features
parameters describing client behavior, protocol messages, topology updates and
even details on internal algorithms and decisisons.

We ``aggregate'' this information as messages and focus on protocol messages,
that is messages regarding the status of the communication (such as download
speed, upload speed) and those with insight on protocol internals
(requests, acknowledgements, connects, disconnects).

As such, there is a separation between periodic, status reporting messages and
internal protocol messages that mostly related to non-periodic events in the
way the protocol works. These have been ``dubbed'' \textit{status messages}
and \textit{verbose messages}.

\textit{Status messages} are periodic messages reporting session state.
Messages are usually output by clients at every second with updated
information regarding number of connected peers, current download speed,
upload speed, estimated time of arrival, download percentage, etc. Status
messages are to be used for real time analysis of peer behaviour as they are
lightweight and periodically output (usually every second).

Status messages may also be used for monitorring, due to their periodic
arrival. When using logging, status messages are typically provided as one
line in a log file and parsed to provide valued information. Graphical
evolution and comparison of various parameters result easily from processing
status messages log files.

\textit{Verbose messages} or \textit{log messages} provide a thorough
inspection of a client's implementation. The output is usually of large
quantity (hundreds of MB per client for a one-day session). Verbose
information is usually stored in client side log files and is subsequently
parsed and stored.

Verbose information may not be easily monitored due to their event-based
creation. When considering the BitTorrent protocol, these messages are
closely related to BitTorrent specification messages such as \texttt{CHOKE},
\texttt{UNCHOKE}, \texttt{REQUEST}, \texttt{HAVE} or internal events in the
implementation. Verobse information may be logged through instrumentation of
client implementation or activation of certain variables. It may also be
determined through investigation of network traffic.

Apart from protocol information provided in status and verbose messages, one
may also collect information regarding application behavior such as the piece
picking algorithm, size of buffers used, overhead information. This data may
be used to fulfill the image of the overall behavior and provide insight on
possible enhancements and improvements.

There are various approaches to collecting information from running clients,
depending on the level of intrusiveness. Some approaches may provide high
detail information, while requiring access to the client source code, while
others provide general information but limited intrusiveness.

The most intrusive approach requires placing hook points into the application
code that provide information. This information may be sent to a monitoring
service, logged, or sent to a logging library. Within the P2P-Next project,
for example, the NextShare core provides an internal API for providing
information. This information is then collected either through a logging
service that collects all information or through the use of a monitoring
service with an HTTP interface and MRTG graphics rendering tools.
Section~\ref{sec:proto-measure:log-library} presents a logging library with
the purpose of collecting logs in an uniform way.

Another approach makes use of logging information directly provided by
BitTorrent clients. There are two disadvantages to this approach. The first
one is that each client provides information in its own way and a dedicated
message parser must be enabled for each application. The second one is related
to receiving verbose messages. In order to be able to receive verbose
messages, one has to turn on the verbose logging. This may be accomplished
through a startup option, an environment variable or a compile option. It may
be the case that non-open source applications possess non of these options and
cannot provide requested information.

Finally, a network-oriented approach requires a throrough analysis of network
packets similar to deep packet inspection. It allows a in depth view of all
packets crossing a given point. Its main advantage is ubiquity: it may be
applied to all clients and implementation regardless of access to the source
code. The disadvantage is the difficulty in parsing all packets and extracting
required information (specific to the BitTorrent protocol) and, perhaps, more
pressing the significant processing overhead introduced.

The messages and information collected are concerned with client behvaior. As
such the applications in place work at the edge of the P2P network on each
client. No information is gathered from the core of the network, inner routers
or the Internet. In order to provide an overall profile of the swarm or P2P
network information collected from all peers must be aggregated and unified.
While having only edge-based information means some data may be lacking it
provides a good perspective of the protocol internals and client
implementation. We dub this approach client-centric investigation.

Collected data may be either monitored, with values rendered in real time or
it may also be archived and compressed for subsequent use. The first approach
requires engaging parsers while data is being generated, while the other
allows use of parsers subsequently. When using parsers with no monitoring,
data is usually stored in a ``database''. ``database'' is a generic term which
may refer to an actual database engine, file system entries, or even memory
information. A rendering or interpretation engine are typically employed to
analyze information in the database and provide it in a valuable form to the
user.

\section{A Generic Logging Library}
\label{sec:proto-measure:log-library}

\todo{hook points}
\todo{architecture}
\todo{output types}
\todo{clients tested}

\section{Log Collecting and Parsing}
\label{sec:proto-measure:log-collect-parse}

\todo{enable, update clients}
\todo{monitoring or post processing}
\todo{experiments}
\todo{data parsing architecture}
\todo{post parsing and real time parsing}
\todo{storage}

\section{Client Logging}
\label{sec:results-logging}

In order to examine BitTorrent transfer at a protocol implementation level, we
propose a system for storing and analysing logging data output by BitTorrent
clients. It currently offers support for hrktorrent/libtorren and Tribler.

Data is provided by BitTorrent clients in log files that are parsed, stored,
interpreted and rendered. We have divided the information generated by clients
into \textbf{status log files} and \textbf{verbose log files}, each composed
of one of the two types of messages described in
Section~\ref{sec:proto-measure:message-types}.

Our study of logging data takes into consideration two open-source BitTorrent
applications: Tribler and hrktorrent\footnote{http://50hz.ws/hrktorrent/}
(based on libtorrent-rasterbar. While the latter needed minimal changes in
order to provide the necessary verbose and status data, Tribler had to be
modified significantly.

The process of configuring Tribler for logging output is completely automated
using shell scripts and may be reversed. The source code alterations are
focused on providing both status and verbose messages as client output
information.

\textit{Status message} information provided by Tribler includes transfer
completion percentage, download and upload rates. In the modified version, it
also outputs current date and time, transfer size, estimated time of arrival
(ETA), number of peers, and the name and path of the transferred file.

In order to enable \textit{verbose message} output, we took advantage of the
fact that Tribler uses flags that can trigger printing to standard output for
various implementation details, among which are the actions related to
receiving and sending BitTorrent messages. The files we identified to be
responsible for protocol data are changed using scripts in order to print the
necessary information and to associate it to a timestamp and date. Since most
of the protocol exchange data was passed through several levels in Tribler's
class hierarchy, attention had to be paid to avoid duplicate output and to
reduce file size. In contrast to libtorrent-rasterbar, which, at each transfer,
creates a separate session log file for each peer, Tribler stores verbose
messages in a single file. This file is passed to the verbose parser, which
extracts relevant parts of the messages and writes them into the database.

Unlike Tribler, hrktorrent's instrumentation did not imply modifying its
source code but defining \texttt{TORRENT\_LOGGING} and
\texttt{TORRENT\_VERBOSE\_LOGGING} macros before building (recompiling)
libtorrent-rasterbar. Minor updates had to be delivered to the compile options
of hrktorrent in order to enable logging output.

Although our system processes and stores all protocol message types,
the most important messages for our swarm analysis are those related to
changing a peer's state (choke/unchoke) and requesting/receiving data.
Correlations between these messages are the heart of provisioning information
about the peers' behaviour and BitTorrent clients' performance.

\section{Data Processing Engine}
\label{sec:proto-measure:data-processing}

As client instrumentation provides in-depth information on client
implementation, it generates extensive input for data analysis. Coupled
with carefully crafted experiments and message filtering, this will allow
the detection of weak spots and of improvement possibilities in current
implementations. Thus it will provide feedback to client and protocol
implementations and swarm ``tuning'' suggestions, which in turn will enable
high performance swarms and rapid content delivery in peer-to-peer systems.

Currently, the infrastructure consists of the following modules:

\begin{itemize}
  \item \textbf{Parsers} -- receive log files provided by BitTorrent
clients during file transfers. Due to differences between log file formats,
there are separate pairs of parsers for each client. Each pair analyses status
and verbose messages.
  \item \textbf{Database Access} -- a thin layer between the database system and
other modules. Provides support for storing messages, updating and reading
them.
  \item \textbf{SQLite Database} -- contains a database schema with tables
designed for storing protocol messages content and peer information.
  \item \textbf{Rendering Engine} -- consists of a GUI application that
processes the information stored in the database and renders it using plots
and other graphical tools.
\end{itemize}

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{src/img/proto-measure/logarch-not-use}
  \end{center}
  \caption{Logging System Overview}
  \label{fig:proto-measure:logarch}
\end{figure}

As shown in Figure~\ref{fig:proto-measure:logarch}, using parsers specific to
each type of logging file, messages are sent as input to the \textit{Database
Access} module that stores them into an SQLite database. In order to analyse
peer behaviour the Rendering Engine reads stored logging data using the
Database Access module and outputs it to a graphical user interface.

Once all logging and verbose data from a given experiment is collected, the
next step is the analysis phase. The testing infrastructure provides a GUI
(\textit{Graphical User Interface}) statistics engine for inspecting peer
behaviour. 

The GUI is implemented in Python using two libraries: \textit{matplotlib}
-- for generating graphs and \textit{TraitsUi} -- for handling widgets. It
offers several important plotting options for describing peer behaviour and
peer interaction during the experiment:

\begin{itemize}
  \item \textit{download/upload speed} -- displays the evolution of
download/upload speed for the peer;
  \item \textit{acceleration} -- shows how fast the download/upload speed of
the peer increases/decreases;
  \item \textit{statistics} -- displays the types and amount of verbose
messages the peer exchanged with other peers.
\end{itemize}

The last two options are important as they provide valuable information about
the performance of the BitTorrent client and how this performance is
influenced by protocol messages exchanged by the client.

\todo{GUI sample}

The \textit{acceleration} option measures how fast a BitTorrent client is able
to download data. High acceleration forms a basic requirement in live
streaming, as it means starting playback of a torrent file with little delay.

The \textit{statistics} option displays the flow of protocol messages. We are
interested in the choke/unchoke messages.

The GUI also offers two modes of operation: \textit{``Single Client Mode''},
in which the user can follow the behaviour of a single peer during a given
experiment, and \textit{``Client Comparison Mode''}, allowing for comparisons
between two peers.

\subsection{Post Processing Framework for Real-Time Log Analysis}

The dubbed post processing framework is used for storing logging information
provided by various BitTorrent clients into a storage area (commonly a
database). An architectural view of the framework is described in Figure TODO.

\todo{details on figure}

The database schema as shown in Figure TODO is used for relational database
engines such as MySQL or SQLite.

\todo{database schema figure}
\todo{details on each table}

\subsubsection{Client Session ID Mapping}

When parsing log files, one has to know the ID of the client session that has
generated the log file. In order to automate the process, there needs to be a
mapping between the log file (or log archive) and the client session ID.

At the same time, the client session ID needs to exist in the
\texttt{client\_sessions} table in the database, together with information
such as BitTorrent client type, download speed limitation, operating system,
hardware specification etc. This information needs to be supplied by the
experimenter in a form that is both easy to create (by the experimenter) and
parse.

A swarm description file is to be supplied by the experimenter. This file consists all required swarm and peer information including the name/location of the log file/archive.

As we consider the INI format to be best suited for this, as it is fairly easy
to create, edit and update, it was chosen to populate initial information. The
experimenter may easily create an INI swarm description file and provide it to
the parser together with the (compressed) log files.

The swarm description file is to be parsed by the experimenter and SQL queries
will populate the database. One entry would go into the \texttt{swarms} table
and a number of entries equal to the number of peers in the swarm description
file would go into the \texttt{client\_sessions} table. As result of these
queries, swarm IDs and client sessions IDs are going to be created when
running SQL insert queries (due to the \texttt{AUTO\_INCREMENT} options). This
IDs are essential for the message parsing process and are going to be written
down in the Logfile-ID-Mapping-File.

The swarm description file parser is going to parse that file and also generate a logfile-id mapping file. The parser is responsible for three actions:
\begin{itemize}
  \item parsing the swarm description file
  \item creating and running SQL insert queries in the \texttt{swarms} and
  \texttt{client\_sessions} tables
  \item create a logfile-id mapping file consisting of mappings between client
  session IDs and log/file
\end{itemize}

A logfile-id mapping file is to be generated by the swarm description parser
and will subsequently be used by the message parser (be it status messages or
verbose messages). The mapping file simply maps a client session ID to a log
file or a compressed set of log files. A sample file is stored in the
repository (source:ppf/log-samples/log-id-mapping/log-id-mapping.sample.ini).
The message parser doesn't need to know client session information; it would
just use the mapping file and populate entries in the \texttt{*\_messages}
tables.

The message parser is going to use the logfile-id mapping file and the log
file (or compressed set of log files) to populate the \texttt{*\_messages}
tables in the database (\texttt{status\_messages},
\texttt{peer\_status\_messages}, \texttt{verbose\_messages}.

The workflow of the entire process is highlighted in Figure TODO.

\todo{figure}
\todo{figure explanaition}

\subsection{Monitoring}

Client monitoring is enabled trough the use of
MonALISA\footnote{http://monalisa.cern.ch/monalisa.htm}. MonALISA-specific
scripts are used to provide required information to the central repository.
The is typically invoked every 5 seconds. The service station collects
required information and sends them to the monitoring repository.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{src/img/proto-measure/monalisa-monitoring}
  \end{center}
  \caption{Monitoring with MonALISA}
  \label{fig:proto-measure:monitoring}
\end{figure}

Figure~\ref{fig:proto-measure:monitoring} is an architectural view of the
monitoring infrastructure. The core component of the monitoring framework is
the MonALISA service. The service is able to discover other monitoring
services and to be discovered by interested clients. Each service registers
itself with a set of Lookup Services (LUSs) as part of a dedicated monitoring
group and it publishes a set of dynamic attributes that describe it. This way
any interested application can request specific services based on a set of
matching attributes.

The service consists of an ensemble of multi-threaded subsystems,
which carry out several functions in an independent fashion, being able to
operate autonomously. Some of the most important functions it
performs are:

\begin{itemize}
  \item monitoring of a large number of entities (hosts running BitTorrent
  test scenarios) using simultaneously several modules which interact actively
  with the entities or passively listen for information, or interface with
  other existing monitoring tools;
  \item filtering and aggregation of the monitoring data, providing additional
  information based on several data series;
  \item storage for short period of time of the monitoring information, in
  memory or in a local database; this way, clients can get also history for
  the monitoring information they are interested in, not only the real-time
  monitored values; web services for direct access to the monitored data, from
  the monitoring service; local clients can get the information directly,
  without following the whole chain;
  \item triggers, alerts and actions based on the monitored P2P information,
  being able to react immediately when abnormal behaviour is detected;
  controlling using dedicated modules allow performing more complicated
  actions, that cannot be taken only to the local flow of information. This
  way, the service can act based on monitoring information from several
  services at the command of a controlling client, or direct or indirect users
  request.
\end{itemize}

The repository collecting monitoring information from the service is basically
a database. Information can be rendered through a web interface, or by using
the MonALISA interactive client interface. The monitoring data repository
offers long history for a few, preconfigured parameters related to BitTorrent
testing environment. The time series for these parameters are stored in a
database for long-term viewing purposes.

Due to the large amount of data (from all the services in community), the
typical usage is for storing aggregated and summary values. For those, it
offers a set of predefined charts in a web application format that allow
selecting among the set of time series and the time interval to plot. The data
repository client has been extended to support automated actions and alerts
based on some configurable triggers.

The two main functions of the data repository are adding new values and
querying the storage for data matching a given predicate. Particular
implementations are available for different purposes: plain text file logging
of data or database backends, values averaged in time or keeping original data
as it was produced, database structures optimized for keeping arbitrary
parameters or structures optimized for a well-known limited set of parameters.
All database-backed storage structures have the option to re-sample the values
on the fly, to provide a uniform time distribution of values.

New storage implementations that fit particular needs can be easily added. The
default database backend for all services is PostgreSQL. Both the Service and
the repository come with a precompiled PostgreSQL package that is used by
default, but the configuration parameters allow pointing to a different
backend. In addition to any permanent storage for the monitoring values a
volatile memory buffer is kept internally, serving as cache for recent data.
The size of this memory buffer is dynamically adjusted function of how much
memory was allocated to the Java Virtual Machine and how much of it is free.
This volatile storage is enough for running a light monitoring service, being
able to serve history requests in the limit of how much data the service was
able to keep in memory.

While the communication mechanism is shared with the interactive client and
the storage layer is the same as the one in the basic MonALISA Service, the
repository web interface is the particularity of this component. Built around
a Tomcat servlet engine and the JFreeChart charting library, the repository
offers a few powerful servlets that cover most of the known use cases: matrix
views of the values, bar, pie and histogram charts, geographical maps, scatter
plots etc. These views are easily configurable either by editing text files or
by using the web interface itself to create new views.

The repository can also act as a global aggregator. It has the same support as
the Service for running filters on the collected data, producing derived
values that can be stored along or instead of the original values. Custom
filters can be implemented to intercept received data (or particular cuts in
it) and act on the values. A particular kind of filters is the automatic
actions framework. Triggered by the monitored data values (comparison with
predefined thresholds, absence of data, arbitrary correlations or custom
pieces of code) automatic action be taken.

\section{Evaluating Peer-to-Peer Performance}
\label{sec:eval-swarm}

The virtualized infrastructure and automated framework provides the necessary
platform for experimental evaluation of Peer-to-Peer implementations and
formal models. Our interest resides in evaluating BitTorrent clients, which
mostly translates to sheer download speed; the higher the download speed, the
better the performance. Obviously, we have to take into account both peer
download speed and swarm download speed. A peer with high download speed that
more or less ``free rides'' on top of the other peers is not desired in a
given swarm.

In order to properly consider a formal evaluation mechanism for performance
evaluation of a Peer-to-Peer ecosystem, several questions must be answered:

\begin{itemize}
  \item What do we measure?
  \item What do we consider for evaluation?
  \item What do we vary? What is influencing the measurement?
  \item How do the above correlate?
  \item What do we consider to be ``better''?
\end{itemize}

The answer to the first question is given by data acquired from status and
verbose log files: protocol messages, number of connections, download and
upload speed, resource usage. This may be acquired through measurements,
monitoring and log files. As mentioned above, we will consider download speed
as an evaluation unit for performance. We consider the other measurable unit
to correlate to the download speed.

The units we may vary include:

\begin{itemize}
  \item hardware resources -- base or virtualized system resources such as
  RAM, CPU, I/O and networking;
  \item peer/system characteristics -- download speed limitation, upload speed
  limitation, connection limitation, existence of a firewall;
  \item Peer-to-Peer implementation -- software application and protocol
  design;
  \item swarm and network characteristics -- number of peers, network
  topology, peer connectivity, network bandwidth, etc.
\end{itemize}

The varying units influence the measured units. Though we will focus mostly on
download speed, the other units also provide influence. If a given peer
receives a boost in its upload speed that means it will also boost download
speed of sever other peers. If a given varying unit would directly influence
upload speed, that will also provide influence over download speed, though it
may not happen directly. It may be easier to detect influence of varying units
over secondary units, such as protocol messages.

As such, we consider a correspondence between varying units and measured
units:

\begin{align}
\label{eq:proto-measure:eval}
Eval(hw, sys, impl, swarm, net) = (protomsg, speed, conn, ruse)
\end{align}

Our goal is to maximize download speed translates in defining and/or adjusting
the most suitable values for the varying units. A proper implementation,
deployed in a proper environment will ensure increased performance.

This leaves answering the last question: \textit{What do we consider
``better''?}. High download speed roughly translated to low download time. In
order to achieve good/better performance, we required minimizing download
time. Download time is, however, a static unit: we only measure it at the end
of the given scenario. As it is influenced by download speed evolution that
is, in its turn, influenced by other factors, we aim to correlate download
time with the evolution of download speed.

If we were to continuously monitor download speed, a pure mathematical formula
for a given peer would be:

\begin{align}
  FS = \int_0^{DT} DS(t)\,dt
\end{align}

where:

\begin{itemize}
  \item FS -- file size
  \item DT -- download time
  \item DS -- download speed (evolution)
\end{itemize}

As we only periodically monitor a peer, the formula translates to:

\begin{align}
  FS = \sum_{t=0}^{DT} DS_{t}
\end{align}

This provides necessary correlation between download speed evolution and
download time, with the file size being well known.

In order to correlate download speed with other units, we have to consider
download speed as the interaction with other peers. A peer may only download
if other peers upload. We formalize this as a download matrix that may
be built for each interval of monitoring:

\begin{align}
  PDS_{t} =
  \begin{pmatrix}
    ds_{1,1} = 0 & ds_{1,2} & \cdots & ds_{1,NP} \\
    ds_{2,1} & ds_{2,2} = 0 & \cdots & ds_{2,NP} \\
    \vdots & \vdots & \ddots & \vdots \\
    ds_{NP,1} & ds_{NP,2} & \cdots & ds_{NP,NP} = 0 \\
  \end{pmatrix}
\end{align}

where:

\begin{itemize}
  \item $ds_{i,j}$ -- download speed of peer \texttt{j} from peer \texttt{i};
  \item \texttt{PDS} -- peer download speed matrix at time \texttt{t};
  \item \texttt{NP} -- number of peers in swarm;
\end{itemize}

Peer to peer download speed is easily measurable and as it fairly easy to
correlate it to varying units. Using an array of such matrices, a matrix
element for each time slice, one will possess detailed measured information
regarding peer download speed and, by summing up either rows, columns or the
whole matrix, provide the ability to observe peer upload speed, peer download
speed and swarm download speed.

The most important step, left as further work is to establish a formal
definition or approximation for Equation~\ref{eq:proto-measure:eval}. This
will allow the establishment of the most important units to be considered and
updated to ensure peer and swarm performance.
